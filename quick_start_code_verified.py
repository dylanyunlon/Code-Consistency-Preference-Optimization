#!/usr/bin/env python3
"""
Quick Start for Code-Verified CCPO Training
ä»£ç éªŒè¯å¢å¼ºCCPOè®­ç»ƒçš„å¿«é€Ÿå¯åŠ¨è„šæœ¬
"""

import asyncio
import argparse
import logging
import os
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from enhanced_ccpo_runner import EnhancedCCPORunner

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description="Quick Start for Code-Verified CCPO Training")
    
    # è¿è¡Œæ¨¡å¼
    parser.add_argument("--mode", choices=["demo", "quick_train", "full_train", "eval"], 
                       default="demo", help="è¿è¡Œæ¨¡å¼")
    
    # æ¨¡å‹ç›¸å…³
    parser.add_argument("--model", type=str, 
                       default="/data/jiacheng/dylan/aaai/Code-Consistency-Preference-Optimization/cppo/mistralai/Mistral-7B-Instruct-v0.2",
                       help="åŸºç¡€æ¨¡å‹è·¯å¾„")
    parser.add_argument("--model_path", type=str,
                       help="å·²è®­ç»ƒæ¨¡å‹è·¯å¾„ï¼ˆç”¨äºè¯„ä¼°ï¼‰")
    
    # è®­ç»ƒå‚æ•°
    parser.add_argument("--max_iterations", type=int, default=3,
                       help="æœ€å¤§è®­ç»ƒè¿­ä»£æ¬¡æ•°")
    parser.add_argument("--batch_size", type=int, default=2,
                       help="æ‰¹å¤§å°")
    parser.add_argument("--learning_rate", type=float, default=5e-7,
                       help="å­¦ä¹ ç‡")
    parser.add_argument("--beta", type=float, default=0.01,
                       help="CCPO betaå‚æ•°")
    
    # éªŒè¯æœåŠ¡å™¨é…ç½®
    parser.add_argument("--verification_url", type=str,
                       default="https://8.134.217.190:17432",
                       help="ä»£ç éªŒè¯æœåŠ¡å™¨URL")
    parser.add_argument("--verification_username", type=str,
                       default="newuser",
                       help="éªŒè¯æœåŠ¡å™¨ç”¨æˆ·å")
    parser.add_argument("--verification_password", type=str,
                       default="newPass123",
                       help="éªŒè¯æœåŠ¡å™¨å¯†ç ")
    
    # è¾“å‡ºé…ç½®
    parser.add_argument("--output_dir", type=str,
                       default="./checkpoints/code-verified-ccpo-test",
                       help="è¾“å‡ºç›®å½•")
    parser.add_argument("--config_file", type=str,
                       default="config.yaml",
                       help="é…ç½®æ–‡ä»¶è·¯å¾„")
    
    return parser.parse_args()

async def demo_mode():
    """æ¼”ç¤ºæ¨¡å¼ - æµ‹è¯•ä»£ç éªŒè¯åŠŸèƒ½"""
    print("ğŸ§ª ä»£ç éªŒè¯æ¼”ç¤ºæ¨¡å¼")
    print("=" * 50)
    
    # æµ‹è¯•éªŒè¯å™¨è¿æ¥
    try:
        from execution_verifier import ExecutionVerifier
        
        async with ExecutionVerifier(
            base_url="https://8.134.217.190:17432",
            username="newuser",
            password="newPass123",
            debug=True
        ) as verifier:
            print("âœ… éªŒè¯å™¨è¿æ¥æˆåŠŸ")
            
            # æµ‹è¯•å•ä¸ªéªŒè¯
            test_question = "strawberryä¸­æœ‰å‡ ä¸ªå­—æ¯rï¼Ÿ"
            test_response = "strawberryä¸­æœ‰3ä¸ªå­—æ¯r"
            
            print(f"æµ‹è¯•é—®é¢˜: {test_question}")
            print(f"æµ‹è¯•å›ç­”: {test_response}")
            print("æ­£åœ¨éªŒè¯...")
            
            result = await verifier.verify_response(test_question, test_response)
            
            print(f"\néªŒè¯ç»“æœ:")
            print(f"  éªŒè¯é€šè¿‡: {'âœ…' if result.verified else 'âŒ'}")
            print(f"  ç½®ä¿¡åº¦: {result.confidence:.3f}")
            print(f"  AIç­”æ¡ˆ: {result.ai_answer}")
            print(f"  ä»£ç ç­”æ¡ˆ: {result.code_answer}")
            print(f"  æ‰§è¡ŒçŠ¶æ€: {result.status.value}")
            print(f"  æ‰§è¡Œæ—¶é—´: {result.execution_time:.2f}s")
            
            if result.stdout:
                print(f"  æ‰§è¡Œè¾“å‡ºé¢„è§ˆ: {result.stdout[:200]}...")
    
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºå¤±è´¥: {e}")
        return False
    
    print("\nâœ… æ¼”ç¤ºå®Œæˆï¼éªŒè¯ç³»ç»Ÿå·¥ä½œæ­£å¸¸ã€‚")
    return True

async def quick_train_mode(args):
    """å¿«é€Ÿè®­ç»ƒæ¨¡å¼ - å°è§„æ¨¡æµ‹è¯•è®­ç»ƒ"""
    print("ğŸš€ å¿«é€Ÿè®­ç»ƒæ¨¡å¼")
    print("=" * 50)
    
    # åˆ›å»ºä¸´æ—¶é…ç½®
    temp_config = {
        "model": {
            "name_or_path": args.model,
            "fp16": True
        },
        "data": {
            "dataset_mixer": {"HuggingFaceH4/ultrafeedback_binarized": 1.0}
        },
        "training": {
            "output_dir": args.output_dir,
            "num_train_epochs": 1,
            "per_device_train_batch_size": args.batch_size,
            "learning_rate": args.learning_rate,
            "beta": args.beta,
            "max_length": 1024,
            "max_prompt_length": 512,
            "loss_type": "code_verified"
        },
        "verification": {
            "enable": True,
            "base_url": args.verification_url,
            "username": args.verification_username,
            "password": args.verification_password,
            "sample_size": 50  # å°æ ·æœ¬å¿«é€Ÿæµ‹è¯•
        }
    }
    
    # ä¿å­˜ä¸´æ—¶é…ç½®
    import yaml
    temp_config_path = "temp_quick_config.yaml"
    with open(temp_config_path, 'w') as f:
        yaml.dump(temp_config, f, default_flow_style=False)
    
    try:
        # è¿è¡Œå¿«é€Ÿè®­ç»ƒ
        runner = EnhancedCCPORunner(temp_config_path)
        model, tokenizer, metrics = await runner.run_code_verified_training()
        
        print("âœ… å¿«é€Ÿè®­ç»ƒå®Œæˆï¼")
        print(f"è®­ç»ƒæŒ‡æ ‡: {metrics}")
        
        return True
        
    except Exception as e:
        print(f"âŒ å¿«é€Ÿè®­ç»ƒå¤±è´¥: {e}")
        return False
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if os.path.exists(temp_config_path):
            os.remove(temp_config_path)

async def full_train_mode(args):
    """å®Œæ•´è®­ç»ƒæ¨¡å¼ - ä½¿ç”¨é…ç½®æ–‡ä»¶è¿›è¡Œå®Œæ•´è®­ç»ƒ"""
    print("ğŸ¯ å®Œæ•´è®­ç»ƒæ¨¡å¼")
    print("=" * 50)
    
    if not os.path.exists(args.config_file):
        print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {args.config_file}")
        print("ä½¿ç”¨ --mode demo ç”Ÿæˆé»˜è®¤é…ç½®æ–‡ä»¶")
        return False
    
    try:
        runner = EnhancedCCPORunner(args.config_file)
        
        if args.max_iterations > 1:
            # è¿è¡Œè‡ªæˆ‘è¿›åŒ–è®­ç»ƒ
            print(f"å¼€å§‹è‡ªæˆ‘è¿›åŒ–è®­ç»ƒï¼Œæœ€å¤§è¿­ä»£æ¬¡æ•°: {args.max_iterations}")
            model, tokenizer, history = await runner.run_self_evolution(args.max_iterations)
            
            print("âœ… è‡ªæˆ‘è¿›åŒ–è®­ç»ƒå®Œæˆï¼")
            print("è¿›åŒ–å†å²:")
            for i, metrics in enumerate(history):
                print(f"  è¿­ä»£ {i+1}: å‡†ç¡®ç‡={metrics.answer_accuracy_rate:.3f}, "
                     f"æˆåŠŸç‡={metrics.execution_success_rate:.3f}")
        else:
            # è¿è¡Œå•æ¬¡è®­ç»ƒ
            print("å¼€å§‹å•æ¬¡ä»£ç éªŒè¯è®­ç»ƒ")
            model, tokenizer, metrics = await runner.run_code_verified_training()
            
            print("âœ… ä»£ç éªŒè¯è®­ç»ƒå®Œæˆï¼")
            print(f"è®­ç»ƒæŒ‡æ ‡: {metrics}")
        
        return True
        
    except Exception as e:
        print(f"âŒ å®Œæ•´è®­ç»ƒå¤±è´¥: {e}")
        return False

async def eval_mode(args):
    """è¯„ä¼°æ¨¡å¼ - è¯„ä¼°å·²è®­ç»ƒçš„æ¨¡å‹"""
    print("ğŸ“Š è¯„ä¼°æ¨¡å¼")
    print("=" * 50)
    
    if not args.model_path:
        print("âŒ è¯„ä¼°æ¨¡å¼éœ€è¦æŒ‡å®š --model_path")
        return False
    
    if not os.path.exists(args.model_path):
        print(f"âŒ æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {args.model_path}")
        return False
    
    try:
        runner = EnhancedCCPORunner(args.config_file)
        metrics = await runner.run_evaluation(args.model_path)
        
        print("âœ… è¯„ä¼°å®Œæˆï¼")
        print(f"æ‰§è¡ŒæˆåŠŸç‡: {metrics['execution_success_rate']:.3f}")
        print(f"ç­”æ¡ˆå‡†ç¡®ç‡: {metrics['answer_accuracy_rate']:.3f}")
        print(f"å¹³å‡ç½®ä¿¡åº¦: {metrics['average_confidence']:.3f}")
        
        return True
        
    except Exception as e:
        print(f"âŒ è¯„ä¼°å¤±è´¥: {e}")
        return False

def create_default_config(args):
    """åˆ›å»ºé»˜è®¤é…ç½®æ–‡ä»¶"""
    from enhanced_ccpo_runner import create_default_config
    
    config = create_default_config()
    
    # æ ¹æ®å‘½ä»¤è¡Œå‚æ•°æ›´æ–°é…ç½®
    config["model"]["name_or_path"] = args.model
    config["training"]["output_dir"] = args.output_dir
    config["training"]["per_device_train_batch_size"] = args.batch_size
    config["training"]["learning_rate"] = args.learning_rate
    config["training"]["beta"] = args.beta
    config["verification"]["base_url"] = args.verification_url
    config["verification"]["username"] = args.verification_username
    config["verification"]["password"] = args.verification_password
    
    return config

def print_usage_tips():
    """æ‰“å°ä½¿ç”¨æç¤º"""
    print("\nğŸ’¡ ä½¿ç”¨æç¤º:")
    print("1. é¦–æ¬¡ä½¿ç”¨ï¼Œå…ˆè¿è¡Œæ¼”ç¤ºæ¨¡å¼æµ‹è¯•ç¯å¢ƒ:")
    print("   python quick_start_code_verified.py --mode demo")
    print()
    print("2. å¿«é€Ÿæµ‹è¯•è®­ç»ƒï¼ˆå°æ ·æœ¬ï¼‰:")
    print("   python quick_start_code_verified.py --mode quick_train")
    print()
    print("3. å®Œæ•´è®­ç»ƒï¼ˆéœ€è¦é…ç½®æ–‡ä»¶ï¼‰:")
    print("   python quick_start_code_verified.py --mode full_train --config_file config.yaml")
    print()
    print("4. æ¨¡å‹è¯„ä¼°:")
    print("   python quick_start_code_verified.py --mode eval --model_path ./checkpoints/model")
    print()
    print("5. è‡ªæˆ‘è¿›åŒ–è®­ç»ƒ:")
    print("   python quick_start_code_verified.py --mode full_train --max_iterations 5")

async def main():
    """ä¸»å‡½æ•°"""
    args = parse_arguments()
    
    print("ğŸ¤– ä»£ç éªŒè¯å¢å¼ºCCPOè®­ç»ƒ - å¿«é€Ÿå¯åŠ¨")
    print("=" * 60)
    print(f"è¿è¡Œæ¨¡å¼: {args.mode}")
    print(f"åŸºç¡€æ¨¡å‹: {args.model}")
    print(f"è¾“å‡ºç›®å½•: {args.output_dir}")
    print(f"éªŒè¯æœåŠ¡å™¨: {args.verification_url}")
    print("=" * 60)
    
    success = False
    
    try:
        if args.mode == "demo":
            success = await demo_mode()
            
        elif args.mode == "quick_train":
            success = await quick_train_mode(args)
            
        elif args.mode == "full_train":
            success = await full_train_mode(args)
            
        elif args.mode == "eval":
            success = await eval_mode(args)
        
        else:
            print(f"âŒ æœªçŸ¥çš„è¿è¡Œæ¨¡å¼: {args.mode}")
    
    except KeyboardInterrupt:
        print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­æ“ä½œ")
    except Exception as e:
        print(f"âŒ è¿è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
    
    if success:
        print("\nğŸ‰ æ“ä½œæˆåŠŸå®Œæˆï¼")
        
        # å¦‚æœæ˜¯æ¼”ç¤ºæ¨¡å¼ï¼Œæä¾›åç»­å»ºè®®
        if args.mode == "demo":
            print("\nğŸ“ åç»­æ­¥éª¤å»ºè®®:")
            print("1. è¿è¡Œå¿«é€Ÿè®­ç»ƒæµ‹è¯•: --mode quick_train")
            print("2. åˆ›å»ºå®Œæ•´é…ç½®æ–‡ä»¶å¹¶è¿è¡Œå®Œæ•´è®­ç»ƒ")
            print("3. ä½¿ç”¨è‡ªæˆ‘è¿›åŒ–æ¨¡å¼è¿›è¡Œå¤šè½®ä¼˜åŒ–")
        
        elif args.mode == "quick_train":
            print(f"\nğŸ“ è®­ç»ƒç»“æœä¿å­˜åœ¨: {args.output_dir}")
            print("ğŸ’¡ å¯ä»¥ä½¿ç”¨ --mode eval è¯„ä¼°æ¨¡å‹æ€§èƒ½")
        
        elif args.mode == "full_train":
            print(f"\nğŸ“ è®­ç»ƒç»“æœä¿å­˜åœ¨: {args.output_dir}")
            print("ğŸ“Š å»ºè®®è¿è¡Œè¯„ä¼°æ£€æŸ¥æ¨¡å‹æ€§èƒ½")
        
        elif args.mode == "eval":
            print("\nğŸ“ˆ è¯„ä¼°ç»“æœå·²ä¿å­˜åˆ°æ¨¡å‹ç›®å½•")
    else:
        print("\nâŒ æ“ä½œå¤±è´¥")
        print_usage_tips()

if __name__ == "__main__":
    asyncio.run(main())